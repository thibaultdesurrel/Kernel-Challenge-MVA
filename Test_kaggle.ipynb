{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9917a58c-9317-4b60-aa7e-2105f96d9fa6",
   "metadata": {},
   "source": [
    "# First test for the kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d025edd8-8947-40f8-8765-3aded42386e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import cvxopt\n",
    "from cvxopt import matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d1d85-4139-4680-8875-48961ef3b55e",
   "metadata": {},
   "source": [
    "The evaluation pages describes how submissions will be scored and how students should format their submissions. The metric is the AUC (area under curve). The data contains 2 classes. \n",
    "## Submission\n",
    "Format Submission files should contain two columns: Id and Prediction. The file should contain a header and have the format described below. Id represents the identifier of the test example, ranging from 1 to 2000. The prediction is the corresponding logit which is a real number Ex: ``` Id,Prediction 1, -1.1 2, 3.2 3, -2.4 4,-0.5 5,2.1 6,0.1 7,-0.9 ``` Below, you will also find a piece of code for reading/writing the data. ```python import pickle as pkl import pandas as pd with open('training_data.pkl', 'rb') as file: train_graphs = pkl.load(file) with open('test_data.pkl', 'rb') as file: test_graphs = pkl.load(file) with open('training_labels.pkl', 'rb') as file: train_labels = pkl.load(file) # define your learning algorithm here # for instance, define an object called ``classifier'' # classifier.train(train_labels,train_graphs) # predict on the test data # for instance, test_preds = classifier.predict(test_graphs) Yte = {'Prediction' : test_preds} dataframe = pd.DataFrame(Yte) dataframe.index += 1 dataframe.to_csv('test_pred.csv',index_label='Id') ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39da8c26-6ebe-4b0a-9b7d-c08c5dda2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/training_data.pkl', 'rb') as file: train_graphs = pkl.load(file)\n",
    "with open('data/test_data.pkl', 'rb') as file: test_graphs = pkl.load(file)\n",
    "with open('data/training_labels.pkl', 'rb') as file: train_labels = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434c24e1-3c89-4d79-8435-b177455ea30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_labels = 2*train_labels-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89238997-f328-465a-96bf-9409fcc79027",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_nodes = []\n",
    "for i in range(len(train_graphs)):\n",
    "    for j in range(len(train_graphs[i].nodes)):\n",
    "        all_labels_nodes.append(train_graphs[i].nodes[j]['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d313cf-5e1d-49f2-9d54-31f8d709c8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36,\n",
       "        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n",
       " array([15755, 68731,  6900,  1014,  1893,  1316,   277,    98,   293,\n",
       "          106,    25,    36,   239,     1,     7,     8,    20,     1,\n",
       "            6,    11,     3,     2,     3,     1,     3,     4,    38,\n",
       "            1,     5,     9,     7,     3,     1,     1,     4,     1,\n",
       "            4,     1,     3,     1,     1,     3,     2,     1,     1,\n",
       "            1,     1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(all_labels_nodes,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe776d63-2e88-436b-8560-d2b877ecdc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_edges = []\n",
    "for i in range(len(train_graphs)):\n",
    "    for e in train_graphs[i].edges:\n",
    "        all_labels_edges.append(train_graphs[i].edges[e]['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822032e6-c016-41e2-b6db-2dcf83487316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([60228,  8812, 28308,   238]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(all_labels_edges,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360a55d-55fe-46c5-8f35-cb97c31a1890",
   "metadata": {},
   "source": [
    "## nth order walk kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d4577945-0198-4d34-ba94-4cbecd9a7b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class walk_kernel:\n",
    "    def __init__(self, order):\n",
    "        self.order = order\n",
    "        \n",
    "    def similarity(self,G1,G2):\n",
    "        # Input : G1,G2 two graphs\n",
    "        # Output : K(G1,G2)\n",
    "        product_graph = nx.cartesian_product(G1,G2)\n",
    "        A = nx.adjacency_matrix(product_graph)\n",
    "        n = A.shape[0]\n",
    "        return np.ones((1,n)).dot(scipy.sparse.csr_matrix.power(A,self.order).dot(np.ones((n,1))))[0,0]\n",
    "    \n",
    "    def kernel(self,X,Y):\n",
    "        # Input : X vector of N graphs, Y vector of M graphs\n",
    "        # Output : K similarity matrix between X and Y\n",
    "        N = len(X)\n",
    "        M = len(Y)\n",
    "        K = np.zeros((N,M))\n",
    "        for i in tqdm(range(N)):\n",
    "            for j in range(i,M):\n",
    "                res = self.similarity(train_graphs[i],train_graphs[j])\n",
    "                K[i,j] = res\n",
    "                K[j,i] = res\n",
    "        return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "27719c33-6ec6-4623-9dd6-f6376957ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_k = walk_kernel(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4ccbbb06-e620-4ee0-a757-4d6dc7410808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_22938/1919052559.py:9: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(product_graph)\n",
      "100%|██████████| 100/100 [00:38<00:00,  2.59it/s]\n"
     ]
    }
   ],
   "source": [
    "#N = len(train_graphs)\n",
    "N = 100\n",
    "K = walk_k.kernel(train_graphs[:N],train_graphs[:N])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be1765-02b7-4ec8-b0da-38d165faa6ac",
   "metadata": {},
   "source": [
    "## Geometric Random Walk Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1610f26-f5ef-4bee-8f87-7db03f2d6407",
   "metadata": {},
   "source": [
    "We have that the Geometric Random Walk Kernel is defined as follows :\n",
    "$$K^{\\infty}(G_1,G_2) = e^T(I - \\lambda A_{\\times})^{-1}e$$\n",
    "where $e$ is the all-ones vector, $A_{\\times}$ is the adjacency matrix of the product graph $G_1 \\times G_2$ and $\\lambda > 0$. The geometric random walk kernel converges only if $\\lambda < \\frac{1}{\\lambda_{\\times}}$ where $\\lambda_{\\times}$ is the largest eigenvalue of $A_{\\times}$. The computation of this kernel is $\\mathcal{O}(n^6)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e8192550-4e49-4fdf-8ed3-83626826cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class geometric_random_kernel:\n",
    "    def __init__(self, lmd):\n",
    "        self.lmd = lmd\n",
    "        \n",
    "    def similarity(self,G1,G2):\n",
    "        # Input : G1,G2 two graphs\n",
    "        # Output : K(G1,G2)\n",
    "        product_graph = nx.cartesian_product(G1,G2)\n",
    "        A = nx.adjacency_matrix(product_graph)\n",
    "        n = A.shape[0]\n",
    "        return (np.ones((1,n))@np.linalg.inv(np.eye(n) - self.lmd*A)@np.ones((n,1)))[0,0]\n",
    "    \n",
    "    def kernel(self,X,Y):\n",
    "        # Input : X vector of N graphs, Y vector of M graphs\n",
    "        # Output : K similarity matrix between X and Y\n",
    "        N = len(X)\n",
    "        M = len(Y)\n",
    "        K = np.zeros((N,M))\n",
    "        for i in tqdm(range(N)):\n",
    "            for j in range(i,M):\n",
    "                res = self.similarity(train_graphs[i],train_graphs[j])\n",
    "                K[i,j] = res\n",
    "                K[j,i] = res\n",
    "        return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2c0aefc0-b918-41de-8b37-c32cdb4eadb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = geometric_random_kernel(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9f0171b6-caed-4818-abc7-75840b9ecd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_22938/2612502025.py:9: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(product_graph)\n",
      "  3%|▎         | 3/100 [00:09<05:07,  3.17s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_22938/528862716.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_22938/2612502025.py\u001b[0m in \u001b[0;36mkernel\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mK\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_22938/2612502025.py\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, G1, G2)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k.kernel(train_graphs[:100],train_graphs[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc958615-41e9-4a9a-abe0-556cb16e4e3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vertex histogram kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca35ebda-8323-41bb-a7e3-9ff0f28c6dcc",
   "metadata": {},
   "source": [
    "This kernel is based on slide 20 of [this presentation](https://www.ic.unicamp.br/~seminarios/palestras/2020/2020s1/2020-02-17.pdf). The vertex label histogram of a graph $G$ is a vector $f = [f_1,...,f_d]^T$ such that $f_i = |\\{v \\in V : l(v) = i\\}|$ for each possible label $i$.\n",
    "Then, we have $$k(G,G') = \\langle f,f' \\rangle$$\n",
    "This is not a complet graph kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cd3e55e-e9eb-4a9b-af7b-c8cb4fed9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vertex_histogramm_kernel:\n",
    "    def __init__(self, biggest_class):\n",
    "        self.biggest_class = biggest_class\n",
    "    \n",
    "    def histogramm(self,G):\n",
    "        labels_G = []\n",
    "        for j in range(len(G.nodes)):\n",
    "            labels_G.append(G.nodes[j]['labels'])\n",
    "        labels_G = np.array(labels_G)\n",
    "\n",
    "        f = np.array([len(labels_G[labels_G==i]) for i in range(self.biggest_class)])\n",
    "        return f\n",
    "    \n",
    "    def similarity(self,G1,G2):\n",
    "        f_1 = self.histogramm(G1)\n",
    "        f_2 = self.histogramm(G2)\n",
    "        return f_1@f_2\n",
    "    \n",
    "    def kernel(self,X,Y):\n",
    "        # Input : X vector of N graphs, Y vector of M graphs\n",
    "        # Output : K similarity matrix between X and Y\n",
    "        N = len(X)\n",
    "        M = len(Y)\n",
    "        K = np.zeros((N,M))\n",
    "        for i in tqdm(range(N)):\n",
    "            for j in range(i,M):\n",
    "                res = self.similarity(train_graphs[i],train_graphs[j])\n",
    "                K[i,j] = res\n",
    "                K[j,i] = res\n",
    "        return K\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eafd70a7-1b44-4f98-8d17-4d0ad970c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = vertex_histogramm_kernel(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3968bbf-0870-41a3-b48e-b0d6e1d94235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 174.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 174.,  263.,  175., ...,  277.,  472.,  643.],\n",
       "       [ 263.,  410.,  267., ...,  420.,  720.,  980.],\n",
       "       [ 175.,  267.,  178., ...,  277.,  472.,  643.],\n",
       "       ...,\n",
       "       [ 277.,  420.,  277., ...,  445.,  760., 1035.],\n",
       "       [ 472.,  720.,  472., ...,  760., 1300., 1770.],\n",
       "       [ 643.,  980.,  643., ..., 1035., 1770., 2410.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.kernel(train_graphs[:100],train_graphs[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69822977-682e-4818-8b7e-8318f4db0ee6",
   "metadata": {},
   "source": [
    "## Weisfeiler-Lehman kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "684689a5-9816-4e54-8438-e3399759171d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9dad9b8af2d917c153b31dd18946bd83'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.weisfeiler_lehman_graph_hash(train_graphs[0],iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b87858b6-0945-40cf-bab2-2fc697bb22ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['bc6b88dc3f535192a81e9083e46bdafc',\n",
       "  'a78f29cd5372131de03565b94594d8eb',\n",
       "  'dd97e9a9b1ed3bb50df216e1112c659d'],\n",
       " 1: ['bc6b88dc3f535192a81e9083e46bdafc',\n",
       "  'a5357d9e80333772a3bfb85018871738',\n",
       "  '11f8cb73d7f48a4130e496c3faf8b44b'],\n",
       " 2: ['cd755ae4b4b31e985b6e3893b878bd2c',\n",
       "  '7baf9cf9014bec34f17bfc7d80883fc3',\n",
       "  '7f512307af7b2e5e201f7fbf214cf246'],\n",
       " 3: ['793295b409f46a69bc4968008523d606',\n",
       "  '859255ca748eaaf285e1bf79a2e3f85d',\n",
       "  '83e831745ce920d06a209b95bbfa3ba0'],\n",
       " 4: ['894dc79574bde41801cac14fd57ec400',\n",
       "  'c9297775b8d1cf7f82e83e24e3bdea7d',\n",
       "  'e9f63642d0d7e9a7bb9254f06145b299'],\n",
       " 5: ['0ea5aaaa75acdcc10dfc8f72ac0d4373',\n",
       "  'ea8f2db97e2d638016bfc33077563172',\n",
       "  '93b7db244e2e280ade325d097be0d3dc'],\n",
       " 6: ['793295b409f46a69bc4968008523d606',\n",
       "  '8bc6d6870a6f494822dc2cdaa78ecb86',\n",
       "  'bc28e3ef3030dc9e27a36489d40f5918'],\n",
       " 7: ['793295b409f46a69bc4968008523d606',\n",
       "  '859255ca748eaaf285e1bf79a2e3f85d',\n",
       "  '2777099f800d4c55aa537da7687b648b'],\n",
       " 8: ['793295b409f46a69bc4968008523d606',\n",
       "  '859255ca748eaaf285e1bf79a2e3f85d',\n",
       "  '2b5bd00896b2acef299937bdb78e403b'],\n",
       " 9: ['894dc79574bde41801cac14fd57ec400',\n",
       "  '22cc2acebbef63ed2115c99daa443c62',\n",
       "  '61215300ffaf7cbca741b8ae66ba23cd'],\n",
       " 10: ['894dc79574bde41801cac14fd57ec400',\n",
       "  '22cc2acebbef63ed2115c99daa443c62',\n",
       "  '61215300ffaf7cbca741b8ae66ba23cd'],\n",
       " 11: ['68f978fe50aca8ee91e0e1f94618c62f',\n",
       "  'b3496d57ca1431116b6fadf050fda2d1',\n",
       "  '402bd85580d76c32795f472009ddd8e0'],\n",
       " 12: ['68f978fe50aca8ee91e0e1f94618c62f',\n",
       "  'b3496d57ca1431116b6fadf050fda2d1',\n",
       "  'a1b082553405961c9ad5f97a822e8d19'],\n",
       " 13: ['68f978fe50aca8ee91e0e1f94618c62f',\n",
       "  'b3496d57ca1431116b6fadf050fda2d1',\n",
       "  'a1b082553405961c9ad5f97a822e8d19'],\n",
       " 14: ['0ea5aaaa75acdcc10dfc8f72ac0d4373',\n",
       "  '421b3fe88fe29552f91a7575568fcd97',\n",
       "  '8c3738c20937781ce43eab0548c8f8aa'],\n",
       " 15: ['0ea5aaaa75acdcc10dfc8f72ac0d4373',\n",
       "  '421b3fe88fe29552f91a7575568fcd97',\n",
       "  '8c3738c20937781ce43eab0548c8f8aa']}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.weisfeiler_lehman_subgraph_hashes(train_graphs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb26af-5ff0-4afa-aa59-bc5e35c40e4d",
   "metadata": {},
   "source": [
    "## Test of SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c4d93878-5639-4ec2-999e-6d8f883efec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVC:\n",
    "    def __init__(self, C, kernel, epsilon = 1e-3):\n",
    "        self.type = 'non-linear'\n",
    "        self.C = C                               \n",
    "        self.kernel = kernel        \n",
    "        self.alpha = None\n",
    "        self.support = None\n",
    "        self.epsilon = epsilon\n",
    "        self.norm_f = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "    \n",
    "    def fit(self, X, y, K):\n",
    "       #### You might define here any variable needed for the rest of the code\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        N = len(y)\n",
    "        #K = kernel(X,X)\n",
    "        M = np.diag(y)@K@np.diag(y)\n",
    "        # Lagrange dual problem\n",
    "        def loss(alpha):\n",
    "            return  (1/2)*alpha.T@M@alpha - np.sum(alpha)#'''--------------dual loss ------------------ '''\n",
    "\n",
    "        # Partial derivate of Ld on alpha\n",
    "        def grad_loss(alpha):\n",
    "            return  M@alpha - np.ones_like(alpha)# '''----------------partial derivative of the dual loss wrt alpha -----------------'''\n",
    "\n",
    "        # Constraints on alpha of the shape :\n",
    "        # -  d - C*alpha  = 0\n",
    "        # -  b - A*alpha >= 0\n",
    "        fun_eq = lambda alpha: alpha.T@y # '''----------------function defining the equality constraint------------------'''        \n",
    "        jac_eq = lambda alpha: y   #'''----------------jacobian wrt alpha of the  equality constraint------------------'''\n",
    "        fun_ineq = lambda alpha: np.concatenate((C*np.ones_like(alpha) - alpha,alpha))  # '''---------------function defining the inequality constraint-------------------'''     \n",
    "        jac_ineq = lambda alpha:  np.concatenate((-np.eye(N),np.eye(N))) # '''---------------jacobian wrt alpha of the  inequality constraint-------------------'''\n",
    "        \n",
    "        constraints = ({'type': 'eq',  'fun': fun_eq, 'jac': jac_eq},\n",
    "                       {'type': 'ineq', \n",
    "                        'fun': fun_ineq , \n",
    "                        'jac': jac_ineq})\n",
    "\n",
    "        optRes = optimize.minimize(fun=lambda alpha: loss(alpha),\n",
    "                                   x0=np.ones(N), \n",
    "                                   method='SLSQP', \n",
    "                                   jac=lambda alpha: grad_loss(alpha), \n",
    "                                   constraints=constraints)\n",
    "        self.alpha = optRes.x\n",
    "        ## Assign the required attributes\n",
    "\n",
    "        indices =  np.where((self.alpha>0) & (self.alpha<C))[0]\n",
    "        self.margin_points = X[indices] #'''------------------- A matrix with each row corresponding to a point that falls on the margin ------------------'''\n",
    "        self.b =  np.mean(y[indices] - self.separating_function(self.margin_points))#''' -----------------offset of the classifier------------------ '''\n",
    "        self.norm_f = self.alpha.T@K@self.alpha # '''------------------------RKHS norm of the function f ------------------------------'''\n",
    "        self.support = X[np.where(self.alpha>self.epsilon)[0]]\n",
    "        \n",
    "    ### Implementation of the separting function $f$ \n",
    "    def separating_function(self,x):\n",
    "        # Input : matrix x of shape N data points times d dimension\n",
    "        # Output: vector of size N\n",
    "        return np.sum(np.diag(self.y*self.alpha)@kernel(self.X,x),axis=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict y values in {-1, 1} \"\"\"\n",
    "        d = self.separating_function(X)\n",
    "        return 2 * (d+self.b> 0) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3151fbc3-f8bc-4679-80a4-077d0d0d6152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:13<00:00, 35.89it/s] \n"
     ]
    }
   ],
   "source": [
    "C = 10\n",
    "N = 500\n",
    "kernel = vertex_histogramm_kernel(49).kernel\n",
    "X = train_graphs[:N]\n",
    "y = new_train_labels[:N]\n",
    "K = kernel(X,X)\n",
    "model = KernelSVC(C=C, kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "62a413d8-af0a-4040-b2b9-b3d67feabbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_22938/673968749.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  model.fit(np.array(X), np.array(y), K)\n",
      "100%|██████████| 500/500 [00:12<00:00, 38.57it/s] \n"
     ]
    }
   ],
   "source": [
    "C = 1\n",
    "model = KernelSVC(C=C, kernel=kernel)\n",
    "model.fit(np.array(X), np.array(y), K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9f229be1-053d-4dc1-8486-8b15e49ea6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:13<00:00, 36.50it/s] \n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fffde702-2472-4e24-b322-d53d5fa5be39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bd64f730-61b6-4435-af21-a8ab4aa47760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,\n",
       "        1, -1,  1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1,  1,\n",
       "       -1, -1,  1, -1, -1,  1, -1,  1, -1,  1, -1, -1,  1,  1, -1,  1,  1,\n",
       "       -1, -1, -1, -1, -1, -1,  1, -1,  1, -1, -1, -1,  1, -1, -1, -1,  1,\n",
       "       -1, -1, -1, -1, -1,  1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,\n",
       "        1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
       "       -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,\n",
       "        1, -1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1,  1,  1, -1,  1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1,  1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1,  1, -1, -1, -1, -1,\n",
       "        1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1,  1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "174304c3-80e0-4729-8fa9-f5d1b2476cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  1]), array([441,  59]))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "42dccdb8-28d4-40cb-a02a-b6637667bf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1]), array([500]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84420b88-11f1-4824-95d9-9aed99da314d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.88159433e+08,  4.01139584e+08,  5.38731638e+08,  1.93186559e+08,\n",
       "        3.39479336e+09,  5.78086417e+08, -3.11367557e+08,  7.42625459e+08,\n",
       "        6.70721048e+08,  2.39735659e+09,  8.92560729e+08,  3.20615012e+08,\n",
       "       -2.82654618e+08, -1.85706411e+09, -3.10520268e+08, -3.11494206e+08,\n",
       "       -3.73483736e+08,  3.05144311e+08, -3.64163821e+08, -2.36502952e+08,\n",
       "       -2.06505347e+09,  9.48532920e+08, -1.53126626e+09, -9.58766064e+08,\n",
       "        1.32354647e+09,  7.17429928e+08,  6.87866708e+08,  4.81810802e+08,\n",
       "        9.08861401e+08, -2.64431990e+08, -1.48332668e+08,  7.76262555e+08,\n",
       "        1.07483675e+09, -3.48985076e+08,  5.12024852e+08,  9.06891605e+08,\n",
       "        2.34259313e+08, -1.27714862e+08,  6.46756240e+08, -2.16602341e+08,\n",
       "       -5.58834480e+07, -8.78954314e+07,  1.02775454e+09,  2.67104344e+08,\n",
       "        7.69685059e+08, -2.96993014e+08, -2.24142876e+08, -2.18548760e+08,\n",
       "       -4.56709446e+08, -2.22377027e+08, -1.01988784e+09,  4.21345512e+09,\n",
       "       -1.45374254e+09, -1.46743578e+09,  4.09962687e+08,  4.76285817e+08,\n",
       "       -1.46797942e+08, -8.47335549e+08,  4.99477597e+09, -2.45518281e+08,\n",
       "       -2.42272306e+08, -1.62433137e+09, -1.58963777e+09, -3.13740514e+08,\n",
       "        2.58752782e+08,  8.90775864e+08, -6.50912062e+08,  3.50233387e+08,\n",
       "       -8.08160280e+08, -2.54954682e+09, -2.25028931e+09, -2.42885124e+08,\n",
       "        1.46880861e+08, -5.06010540e+08,  1.79263526e+08,  1.05808132e+09,\n",
       "       -3.29164445e+08,  9.95478422e+08, -2.64410078e+08, -2.51697444e+08,\n",
       "       -1.98245567e+09, -1.53126626e+09, -1.53126626e+09,  1.54009457e+09,\n",
       "        4.46162444e+08, -7.15999221e+07, -1.29043015e+09, -1.27786937e+09,\n",
       "       -2.00113681e+09, -1.73355414e+09,  6.21256049e+08,  3.05300112e+08,\n",
       "       -1.17372020e+08, -1.17255188e+09,  6.94423356e+08,  9.40284983e+08,\n",
       "       -4.27067230e+07, -1.53126626e+09,  2.21441835e+09,  2.04214915e+09])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc32c8ce-dae2-4a9f-a179-1835f6e80986",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fde97875-274c-425e-ba13-7fdba2ac20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correct(true_y,predicted_y):\n",
    "    return np.sum(true_y == predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b86addd5-d908-4425-bddf-6e0220e75f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/ (1 + np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3a67f021-37ae-408e-a69e-28afd6873fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, lamb, kernel, eps = 1e-6, thresh = 0):\n",
    "        \"\"\" \n",
    "        Parameters :\n",
    "        lamb : float, regularization paramter\n",
    "        eps : float, minimum tolerance\n",
    "        thresh : float, minimum threshold for the prediction\n",
    "        \"\"\"\n",
    "        self.lamb = lamb\n",
    "        self.kernel = kernel\n",
    "        self.eps = eps\n",
    "        self.threshold = thresh\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.alpha = None\n",
    "    \n",
    "    def fit(self, X, y, K, nb_iter = 10):\n",
    "        \"\"\"\n",
    "        Parameters :\n",
    "        X : array of training data (nb_samples x nb_features)\n",
    "        y : list of training labels in {-1,1} (nb_samples)\n",
    "        K : precomputed Gram matrix of X using kernel (nb_samples x nb_samples)\n",
    "        \n",
    "        Returns :\n",
    "        alpha : nb_samples array\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        nb_samples = len(X)\n",
    "        \n",
    "        alpha = np.zeros(nb_samples)\n",
    "        \n",
    "        # Solve the KLR optimization problem by IRLS\n",
    "        for i in range(nb_iter):\n",
    "            new_alpha = alpha.copy()\n",
    "            m = K@alpha\n",
    "            W = sigmoid(m) * sigmoid(-m)\n",
    "            z = m + y / sigmoid(-y * m)\n",
    "            \n",
    "            W_sqrt = np.sqrt(W)\n",
    "            new_alpha = W_sqrt * np.linalg.solve(W_sqrt * K * W_sqrt.T + nb_samples * self.lamb * np.eye(nb_samples), W_sqrt * y)\n",
    "            \n",
    "            # If we have reached eps-close to the previous iterate, we stop\n",
    "            if np.linalg.norm(alpha - new_alpha) < self.eps:\n",
    "                alpha = new_alpha.copy()\n",
    "                print(\"Stopped because convergence was reached at iteration\", i)\n",
    "                break\n",
    "            \n",
    "            alpha = new_alpha.copy()\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        #return alpha\n",
    "    \n",
    "    def predict_logit(self,X):\n",
    "        \"\"\"\n",
    "        Parameters :\n",
    "        X : array of data for which we want to predict the label (nb_samples x nb_features)\n",
    "        \n",
    "        Returns :\n",
    "        Array of the predicted logits (n_samples)\n",
    "        \"\"\"\n",
    "        K = self.kernel(X,self.X)\n",
    "        return K@self.alpha\n",
    "    \n",
    "    def predict_class(self, X):\n",
    "        \"\"\"\n",
    "        Parameters :\n",
    "        X : array of data for which we want to predict the label (nb_samples x nb_features)\n",
    "        \n",
    "        Returns :\n",
    "        Array of the predicted labels (n_samples)\n",
    "        \"\"\"\n",
    "        K = self.kernel(X, self.X)\n",
    "        y = np.dot(K, self.alpha)\n",
    "        return np.where(y > self.threshold, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9558f09-ee8f-4762-8367-c537d3f04b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.walk_kernel at 0x7fa4048d9880>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walk_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6f207155-2af1-476d-8e8a-8a49070a29ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_22938/2612502025.py:9: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(product_graph)\n",
      "100%|██████████| 100/100 [04:27<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "X = train_graphs[:N]\n",
    "y = new_train_labels[:N]\n",
    "K = k.kernel(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "21452197-266a-4e6c-972d-8cc70dec5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(1, k.kernel)\n",
    "model.fit(X, y, K, nb_iter = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2bc8f021-57ef-4727-8778-0c143ce7fcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_22938/2612502025.py:9: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(product_graph)\n",
      "100%|██████████| 100/100 [05:10<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_class(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "646ffe35-92a0-49b6-8c5b-ead040fc6c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_correct(y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5c41977f-4990-44a9-a6fa-a0bb75818859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8db9a58c-9b9d-4fa7-9a40-06605175ad75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 266.68800223,  400.38814767,  300.36986129, ...,  384.42605396,\n",
       "         633.38684377,  867.45937936],\n",
       "       [ 400.38814767,  601.11741291,  450.95638718, ...,  577.15393721,\n",
       "         950.92611964, 1302.34853248],\n",
       "       [ 300.36986129,  450.95638718,  338.30607827, ...,  432.97925684,\n",
       "         713.38162445,  977.01775068],\n",
       "       ...,\n",
       "       [ 384.42605396,  577.15393721,  432.97925684, ...,  554.14777   ,\n",
       "         913.01599171, 1250.43045255],\n",
       "       [ 633.38684377,  950.92611964,  713.38162445, ...,  913.01599171,\n",
       "        1504.30049551, 2060.22527408],\n",
       "       [ 867.45937936, 1302.34853248,  977.01775068, ..., 1250.43045255,\n",
       "        2060.22527408, 2821.59802272]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c735f6-9b74-4a44-bc2d-a4fe8628e501",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a92ae8f3-37e7-41d0-b776-e87c3f61d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, C, kernel, thresh=1e-3):\n",
    "        \"\"\" \n",
    "        Parameters :\n",
    "        C : float, regularization paramter\n",
    "        thresh : float, minimum threshold for the prediction\n",
    "        \"\"\"\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.threshold = thresh\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.alpha = None\n",
    "        self.support_vectors_indices = None\n",
    "        self.support_vectors = None\n",
    "        \n",
    "    def fit(self, X, y, K, nb_iter = 10):\n",
    "        \"\"\"\n",
    "        Parameters :\n",
    "        X : array of training data (nb_samples x nb_features)\n",
    "        y : list of training labels in {-1,1} (nb_samples)\n",
    "        K : precomputed Gram matrix of X using kernel (nb_samples x nb_samples)\n",
    "        \n",
    "        Returns :\n",
    "        alpha : nb_samples array\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        nb_samples = len(X)\n",
    "        \n",
    "        # We start by defining the different quantities we need in order to solve our problem\n",
    "\n",
    "        P = matrix(K)\n",
    "        q = matrix(-y.astype('float'))\n",
    "        G = matrix(np.block([[np.diag(np.squeeze(y).astype('float'))],[-np.diag(np.squeeze(y).astype('float'))]]))\n",
    "        h = matrix(np.concatenate((self.C*np.ones(nb_samples),np.zeros(nb_samples))))\n",
    "\n",
    "        #Solve the problem using cvxopt\n",
    "        solver = cvxopt.solvers.qp(P=P,q=q,G=G,h=h)\n",
    "        solution = solver['x']\n",
    "        self.alpha = np.squeeze(np.array(solution))\n",
    "\n",
    "        #Retrieve the support vectors\n",
    "        self.support_vectors_indices = np.squeeze(np.abs(np.array(solution))) > self.threshold\n",
    "        self.alpha = self.alpha[self.support_vectors_indices]\n",
    "        self.support_vectors = self.X[self.support_vectors_indices]\n",
    "    \n",
    "    def predict_logit(self,X):\n",
    "        \"\"\"\n",
    "        Parameters :\n",
    "        X : array of data for which we want to predict the label (nb_samples x nb_features)\n",
    "        \n",
    "        Returns :\n",
    "        Array of the predicted logits (n_samples)\n",
    "        \"\"\"\n",
    "        K = self.kernel(X,self.support_vectors)\n",
    "        return K@self.alpha\n",
    "    \n",
    "    def predict_class(self, X):\n",
    "        \"\"\"\n",
    "        Parameters :\n",
    "        X : array of data for which we want to predict the label (nb_samples x nb_features)\n",
    "        \n",
    "        Returns :\n",
    "        Array of the predicted labels (n_samples)\n",
    "        \"\"\"\n",
    "        K = self.kernel(X, self.support_vectors)\n",
    "        y = np.dot(K, self.alpha)\n",
    "        return np.where(y > self.threshold, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "eaa0bc1f-054c-4c70-befe-931378b9959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_22938/4117056514.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.array(train_graphs)[idx]\n",
      "100%|██████████| 500/500 [00:12<00:00, 38.72it/s] \n"
     ]
    }
   ],
   "source": [
    "N = 500\n",
    "k = vertex_histogramm_kernel(49)\n",
    "idx = np.random.choice(np.arange(len(train_graphs)),size = N, replace=False)\n",
    "X = np.array(train_graphs)[idx]\n",
    "y = new_train_labels[idx]\n",
    "K = k.kernel(X,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1afa07a1-ed8c-4519-b0c0-575d7a969a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3138e+03 -6.2305e+04  2e+05  1e+00  1e-11\n",
      " 1: -1.0616e+03 -3.2130e+04  5e+04  2e-01  9e-12\n",
      " 2: -9.6028e+02 -8.1225e+03  8e+03  3e-02  7e-12\n",
      " 3: -1.0567e+03 -2.6288e+03  2e+03  4e-03  8e-12\n",
      " 4: -1.1526e+03 -2.2973e+03  1e+03  3e-03  7e-12\n",
      " 5: -1.2617e+03 -1.8662e+03  6e+02  1e-03  8e-12\n",
      " 6: -1.3476e+03 -1.6257e+03  3e+02  5e-04  7e-12\n",
      " 7: -1.4004e+03 -1.5157e+03  1e+02  2e-04  1e-11\n",
      " 8: -1.4233e+03 -1.4707e+03  5e+01  6e-05  8e-12\n",
      " 9: -1.4352e+03 -1.4499e+03  1e+01  1e-05  8e-12\n",
      "10: -1.4387e+03 -1.4444e+03  6e+00  5e-06  9e-12\n",
      "11: -1.4398e+03 -1.4425e+03  3e+00  2e-06  9e-12\n",
      "12: -1.4408e+03 -1.4411e+03  3e-01  2e-16  1e-11\n",
      "13: -1.4409e+03 -1.4409e+03  3e-03  2e-16  1e-11\n",
      "14: -1.4409e+03 -1.4409e+03  3e-05  2e-16  9e-12\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "model = SVM(10, k.kernel)\n",
    "model.fit(X, y, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bb98aa35-cbe5-4dc4-a49f-884f08c645dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:01<00:00, 355.25it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_class(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f5aeb9d3-fc3b-4145-989d-c12bf9032e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_correct(y,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "01e26e3e-cc11-4fe8-a565-782b26d199b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1]), array([500]))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88332bb-ef22-4ff4-bd00-a57342635e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
