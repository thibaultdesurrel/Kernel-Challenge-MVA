{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9917a58c-9317-4b60-aa7e-2105f96d9fa6",
   "metadata": {},
   "source": [
    "# First test for the kaggle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d025edd8-8947-40f8-8765-3aded42386e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d1d85-4139-4680-8875-48961ef3b55e",
   "metadata": {},
   "source": [
    "The evaluation pages describes how submissions will be scored and how students should format their submissions. The metric is the AUC (area under curve). The data contains 2 classes. \n",
    "## Submission\n",
    "Format Submission files should contain two columns: Id and Prediction. The file should contain a header and have the format described below. Id represents the identifier of the test example, ranging from 1 to 2000. The prediction is the corresponding logit which is a real number Ex: ``` Id,Prediction 1, -1.1 2, 3.2 3, -2.4 4,-0.5 5,2.1 6,0.1 7,-0.9 ``` Below, you will also find a piece of code for reading/writing the data. ```python import pickle as pkl import pandas as pd with open('training_data.pkl', 'rb') as file: train_graphs = pkl.load(file) with open('test_data.pkl', 'rb') as file: test_graphs = pkl.load(file) with open('training_labels.pkl', 'rb') as file: train_labels = pkl.load(file) # define your learning algorithm here # for instance, define an object called ``classifier'' # classifier.train(train_labels,train_graphs) # predict on the test data # for instance, test_preds = classifier.predict(test_graphs) Yte = {'Prediction' : test_preds} dataframe = pd.DataFrame(Yte) dataframe.index += 1 dataframe.to_csv('test_pred.csv',index_label='Id') ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "39da8c26-6ebe-4b0a-9b7d-c08c5dda2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/training_data.pkl', 'rb') as file: train_graphs = pkl.load(file)\n",
    "with open('data/test_data.pkl', 'rb') as file: test_graphs = pkl.load(file)\n",
    "with open('data/training_labels.pkl', 'rb') as file: train_labels = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "434c24e1-3c89-4d79-8435-b177455ea30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_labels = 2*train_labels-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6360a55d-55fe-46c5-8f35-cb97c31a1890",
   "metadata": {},
   "source": [
    "## nth order walk kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d4577945-0198-4d34-ba94-4cbecd9a7b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class walk_kernel:\n",
    "    def __init__(self, order):\n",
    "        self.order = order\n",
    "        \n",
    "    def similarity(self,G1,G2):\n",
    "        # Input : G1,G2 two graphs\n",
    "        # Output : K(G1,G2)\n",
    "        product_graph = nx.cartesian_product(G1,G2)\n",
    "        A = nx.adjacency_matrix(product_graph)\n",
    "        n = A.shape[0]\n",
    "        return (np.ones((1,n))@np.power(A,self.order)@np.ones((n,1)))[0,0]\n",
    "    \n",
    "    def kernel(self,X,Y):\n",
    "        # Input : X vector of N graphs, Y vector of M graphs\n",
    "        # Output : K similarity matrix between X and Y\n",
    "        N = len(X)\n",
    "        M = len(Y)\n",
    "        K = np.zeros((N,M))\n",
    "        for i in tqdm(range(N)):\n",
    "            for j in range(i,M):\n",
    "                res = self.similarity(train_graphs[i],train_graphs[j])\n",
    "                K[i,j] = res\n",
    "                K[j,i] = res\n",
    "        return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "27719c33-6ec6-4623-9dd6-f6376957ce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_kernel_1 = walk_kernel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b80a119c-5dc6-40fc-ace5-49940b335e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_9222/3148421536.py:9: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(product_graph)\n"
     ]
    }
   ],
   "source": [
    "#N = len(train_graphs)\n",
    "N = 60\n",
    "K = walk_kernel_1.kernel(train_graphs[:N],train_graphs[:N])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb26af-5ff0-4afa-aa59-bc5e35c40e4d",
   "metadata": {},
   "source": [
    "## Test of SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c4d93878-5639-4ec2-999e-6d8f883efec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSVC:\n",
    "    def __init__(self, C, kernel, epsilon = 1e-3):\n",
    "        self.type = 'non-linear'\n",
    "        self.C = C                               \n",
    "        self.kernel = kernel        \n",
    "        self.alpha = None\n",
    "        self.support = None\n",
    "        self.epsilon = epsilon\n",
    "        self.norm_f = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "    \n",
    "    def fit(self, X, y,K):\n",
    "       #### You might define here any variable needed for the rest of the code\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        N = len(y)\n",
    "        #K = kernel(X,X)\n",
    "        M = np.diag(y)@K@np.diag(y)\n",
    "        # Lagrange dual problem\n",
    "        def loss(alpha):\n",
    "            return  (1/2)*alpha.T@M@alpha - np.sum(alpha)#'''--------------dual loss ------------------ '''\n",
    "\n",
    "        # Partial derivate of Ld on alpha\n",
    "        def grad_loss(alpha):\n",
    "            return  M@alpha - np.ones_like(alpha)# '''----------------partial derivative of the dual loss wrt alpha -----------------'''\n",
    "\n",
    "        # Constraints on alpha of the shape :\n",
    "        # -  d - C*alpha  = 0\n",
    "        # -  b - A*alpha >= 0\n",
    "        fun_eq = lambda alpha: alpha.T@y # '''----------------function defining the equality constraint------------------'''        \n",
    "        jac_eq = lambda alpha: y   #'''----------------jacobian wrt alpha of the  equality constraint------------------'''\n",
    "        fun_ineq = lambda alpha: np.concatenate((C*np.ones_like(alpha) - alpha,alpha))  # '''---------------function defining the inequality constraint-------------------'''     \n",
    "        jac_ineq = lambda alpha:  np.concatenate((-np.eye(N),np.eye(N))) # '''---------------jacobian wrt alpha of the  inequality constraint-------------------'''\n",
    "        \n",
    "        constraints = ({'type': 'eq',  'fun': fun_eq, 'jac': jac_eq},\n",
    "                       {'type': 'ineq', \n",
    "                        'fun': fun_ineq , \n",
    "                        'jac': jac_ineq})\n",
    "\n",
    "        optRes = optimize.minimize(fun=lambda alpha: loss(alpha),\n",
    "                                   x0=np.ones(N), \n",
    "                                   method='SLSQP', \n",
    "                                   jac=lambda alpha: grad_loss(alpha), \n",
    "                                   constraints=constraints)\n",
    "        self.alpha = optRes.x\n",
    "        ## Assign the required attributes\n",
    "\n",
    "        indices =  np.where((self.alpha>0) & (self.alpha<C))[0]\n",
    "        self.margin_points = X[indices] #'''------------------- A matrix with each row corresponding to a point that falls on the margin ------------------'''\n",
    "        self.b =  np.mean(y[indices] - self.separating_function(self.margin_points))#''' -----------------offset of the classifier------------------ '''\n",
    "        self.norm_f = self.alpha.T@K@self.alpha # '''------------------------RKHS norm of the function f ------------------------------'''\n",
    "        self.support = X[np.where(self.alpha>self.epsilon)[0]]\n",
    "        \n",
    "    ### Implementation of the separting function $f$ \n",
    "    def separating_function(self,x):\n",
    "        # Input : matrix x of shape N data points times d dimension\n",
    "        # Output: vector of size N\n",
    "        return np.sum(np.diag(self.y*self.alpha)@kernel(self.X,x),axis=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict y values in {-1, 1} \"\"\"\n",
    "        d = self.separating_function(X)\n",
    "        return 2 * (d+self.b> 0) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3151fbc3-f8bc-4679-80a4-077d0d0d6152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_9222/4105415923.py:9: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(product_graph)\n",
      "100%|██████████| 60/60 [00:15<00:00,  3.93it/s]\n"
     ]
    }
   ],
   "source": [
    "C=1\n",
    "kernel = walk_kernel(1).kernel\n",
    "X = train_graphs[:60]\n",
    "y = new_train_labels[:60]\n",
    "K = kernel(X,X)\n",
    "model = KernelSVC(C=C, kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "62a413d8-af0a-4040-b2b9-b3d67feabbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_9222/3340371026.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  model.fit(np.array(X), np.array(y), K)\n",
      "  0%|          | 0/60 [00:00<?, ?it/s]/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_9222/4105415923.py:9: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(product_graph)\n",
      "100%|██████████| 60/60 [00:11<00:00,  5.33it/s]\n"
     ]
    }
   ],
   "source": [
    "C = 1.\n",
    "model = KernelSVC(C=C, kernel=kernel)\n",
    "model.fit(np.array(X), np.array(y), K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9f229be1-053d-4dc1-8486-8b15e49ea6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]/var/folders/_d/xgqzpq6x1dn227pxd6dvmhsc0000gn/T/ipykernel_9222/4105415923.py:9: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(product_graph)\n",
      "100%|██████████| 60/60 [00:15<00:00,  3.98it/s]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fffde702-2472-4e24-b322-d53d5fa5be39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bd64f730-61b6-4435-af21-a8ab4aa47760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1,\n",
       "        1, -1,  1, -1, -1, -1, -1, -1, -1,  1, -1, -1,  1, -1, -1, -1,  1,\n",
       "       -1, -1,  1, -1, -1,  1, -1,  1, -1,  1, -1, -1,  1,  1, -1,  1,  1,\n",
       "       -1, -1, -1, -1, -1, -1,  1, -1,  1])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174304c3-80e0-4729-8fa9-f5d1b2476cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
